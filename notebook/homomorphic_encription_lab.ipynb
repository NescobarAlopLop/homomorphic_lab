{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homomorphic encription lab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Fi-IRin6ZI"
      },
      "source": [
        "# Homomorphic Encryption (HE) Laboratory Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iZqL3LJou_k"
      },
      "source": [
        "First things first we need to install 2 libraries and downlaod repository with dataset.\n",
        "- TenSEAL is a library for doing homomorphic encryption operations on tensors, built on top of Microsoft SEAL\n",
        "- Python Speach Features - is needed to extract features from audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHZxRYAujXrm",
        "outputId": "aa282863-5652-454e-b6b8-2a89026752f0"
      },
      "source": [
        "!pip install tenseal\n",
        "!pip install python_speech_features\n",
        "!git clone https://github.com/NescobarAlopLop/homomorhpic_lab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tenseal\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/20/a4106c3eff920eccbe040276ed869193fadd8fbbc52307dd6922a453f085/tenseal-0.3.0-cp36-cp36m-manylinux2014_x86_64.whl (4.4MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4MB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.0\n",
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5890 sha256=95619cb0ddd080c67ea07f04f38febcb278fb1d088497729ee0100e36478ef5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n",
            "Cloning into 'homomorhpic_lab'...\n",
            "remote: Enumerating objects: 533, done.\u001b[K\n",
            "remote: Counting objects: 100% (533/533), done.\u001b[K\n",
            "remote: Compressing objects: 100% (452/452), done.\u001b[K\n",
            "remote: Total 533 (delta 133), reused 467 (delta 67), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (533/533), 47.48 MiB | 15.21 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6ew-iFpOV9"
      },
      "source": [
        "Nonthing special, just import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6a7wYU9pWTo"
      },
      "source": [
        "import codecs\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import python_speech_features as psf\n",
        "import scipy.io.wavfile as sw\n",
        "import tenseal as ts\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFY4RNKpaDY"
      },
      "source": [
        "Read dataset and extract features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0eRBicqqXoC",
        "outputId": "c081e110-0253-44e4-b5fa-3f76f405db4c"
      },
      "source": [
        "audio_files_directory = '/content/homomorhpic_lab/model_training/training_data'\n",
        "\n",
        "\n",
        "final_dataset = pd.DataFrame()\n",
        "\n",
        "number_of_filters = 26\n",
        "for file_name in os.listdir(audio_files_directory):\n",
        "    if not os.path.isfile(os.path.join(audio_files_directory, file_name)):\n",
        "        continue\n",
        "\n",
        "    rate, signal = sw.read(os.path.join(audio_files_directory, file_name))\n",
        "    features = psf.base.mfcc(signal=signal, samplerate=rate, preemph=1.1, nfilt=number_of_filters, numcep=17)\n",
        "    features = psf.base.fbank(\n",
        "        signal=features,\n",
        "        samplerate=rate,\n",
        "    )[1]\n",
        "    features = psf.base.logfbank(features)\n",
        "    features_df = pd.DataFrame(features)\n",
        "\n",
        "    if 'dog' in file_name:\n",
        "        features_df['label'] = '-1'\n",
        "    elif 'cat' in file_name:\n",
        "        features_df['label'] = '1'\n",
        "    else:\n",
        "        raise ValueError(f'Unsupported animal class {file_name}')\n",
        "\n",
        "    final_dataset = final_dataset.append(features_df, ignore_index=True)\n",
        "\n",
        "\n",
        "print(f'Dataset shape: {final_dataset.shape}')\n",
        "\n",
        "# Finalize dataset with the attributes and target\n",
        "X = final_dataset.iloc[:, 0:-1]\n",
        "y = final_dataset.iloc[:, -1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape: (270, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re3mGrqwqe_B"
      },
      "source": [
        "To improve training and ease on HE computation I scale the data. And save scaling arguments for feature extraction during testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhNi9WGFriEE"
      },
      "source": [
        "# Splitting into test and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=1)\n",
        "train_mean = np.array(X_train.mean())\n",
        "tran_standard_deviation = np.array(X_train.std())\n",
        "\n",
        "# Feature Scaling\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "\n",
        "X_test = sc.fit_transform(X_test)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klO3X6rpr7OZ"
      },
      "source": [
        "Create and train SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64DSXC1sr-dW",
        "outputId": "4bd8bd7b-be53-43d8-cb8a-f43b3c49a92b"
      },
      "source": [
        "model = svm.SVC(\n",
        "  kernel='poly',\n",
        "  C=20,\n",
        "  gamma=10,\n",
        ")\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=20, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=10, kernel='poly',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE8iQdGjr_MD"
      },
      "source": [
        "As every datascientis and good student knows we only test quality of a trained model on part of the data we have never seen.\n",
        "So here we go:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiUxyt1asOml",
        "outputId": "70e27bae-c2be-44cd-b1fe-e706dcdba318"
      },
      "source": [
        "accuracy_score = model.score(X_test, y_test)\n",
        "print(f'accuracy_score: {accuracy_score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score: 0.7538461538461538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZLBcMgUskBe"
      },
      "source": [
        "Two predictions just go give a small test of the coming amazing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtU7ssi3s031",
        "outputId": "59b31ff1-acec-40ef-be2e-e817781c0c41"
      },
      "source": [
        "print(f'this should be {y_train.iloc[0]} a.k.a. dog: {model.predict(np.array(X_train.iloc[0,:]).reshape((1,26)))}')\n",
        "print(f'this should be {y_train.iloc[1]} a.k.a. cat: {model.predict(np.array(X_train.iloc[1,:]).reshape((1,26)))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this should be -1 a.k.a. dog: ['-1']\n",
            "this should be 1 a.k.a. cat: ['1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tju0IATks53O"
      },
      "source": [
        "# Homomorphic Encription example\n",
        "We finally here, this is officially the fun part!\n",
        "\n",
        "We have a trained SVM model, and we have some data. Which in our case are recordings of cats meow and dogs bark.\n",
        "Now lets assume that for some reason we are unable to tell the two apart, but we also do not want to whoever owns the server, or the \"cloud\" to know what animals do we have.\n",
        "\n",
        "So how one does it? How can we run inference on a remote server without discovering our data?\n",
        "\n",
        "**Homomorphic encryption to the resque!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmkEA5tGu0v9"
      },
      "source": [
        "## This code is ran on \"imaginary\" client side:\n",
        "\n",
        "First we generate SEAL context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpo7PJ_8u6-I"
      },
      "source": [
        "context = ts.context(\n",
        "    ts.SCHEME_TYPE.CKKS,\n",
        "    poly_modulus_degree=8192 * 2,\n",
        "    coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 40, 60]\n",
        ")\n",
        "context.generate_galois_keys()\n",
        "context.global_scale = 2**40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbHODjKPvQvk"
      },
      "source": [
        "Now lets load a test query:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexer4YSvzYL"
      },
      "source": [
        "rate, signal = sw.read(os.path.join(audio_files_directory, 'cat_21.wav'))\n",
        "features = psf.base.mfcc(signal=signal, samplerate=rate, preemph=1.1, nfilt=number_of_filters, numcep=17)\n",
        "features = psf.base.fbank(features)[1]\n",
        "features = psf.base.logfbank(features)\n",
        "query = np.array(features)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ama9qvv2ND"
      },
      "source": [
        "Since we've trained our model on scaled data, we need to scale the queries as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5DOm9qyvZ-t"
      },
      "source": [
        "scaled_query = np.array((query - train_mean) / tran_standard_deviation).reshape((1, 26))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5xDYfGPwFMp"
      },
      "source": [
        "Now we can encrypt the query:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XUvGPlRwFZf"
      },
      "source": [
        "enc_query = ts.ckks_vector(context, scaled_query.tolist()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5FmcHrGwV8D"
      },
      "source": [
        "here we imagine that we've send the encrypted query to remote server. And the next cells are ran on \"imaginary\" server:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lenL8q4PxQV5"
      },
      "source": [
        "## This code is ran on \"imaginary\" server\n",
        "To make things easier on the reader lets extract the required learned vectors from the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX9I-VzSzVT8"
      },
      "source": [
        "bias = model.intercept_[0]\n",
        "degree = model.degree\n",
        "support_vectors = model.support_vectors_\n",
        "gamma = model.gamma\n",
        "dual_coefficients = model.dual_coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC44QEUL0CwZ"
      },
      "source": [
        "And so inference part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1oqltcNwjPG"
      },
      "source": [
        "kernel = enc_query.matmul(support_vectors.T.tolist()) * gamma\n",
        "poly_kernel = kernel.square() * kernel\n",
        "\n",
        "prediction_enc = poly_kernel.dot(dual_coefficients[0].tolist()) + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alqt-WaK0WgS"
      },
      "source": [
        "Just to be sure that the server has \"no idea\" what was the encripted query and the resulting prediction lets print them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBZq-zz20xxX",
        "outputId": "38109780-a77f-4646-bc02-0f97a8ca9eaa"
      },
      "source": [
        "print(f'encrypted query: {enc_query.data}')\n",
        "print(f'encrypted prediction: {prediction_enc.data}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encrypted query: <_tenseal_cpp.CKKSVector object at 0x7fa9899ccae8>\n",
            "encrypted prediction: <_tenseal_cpp.CKKSVector object at 0x7fa9899cc7d8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P445Hyhv1TIm"
      },
      "source": [
        "Back to the client, lets imagine that encrypted result was transfered back to the client side and \n",
        "## the following code is ran on the client side:\n",
        "\n",
        "All whats left to do is to decrypt the prediction.\n",
        "For the reader lets add 2 more lines that will do the inference as it would have been done without encryption, just to compare the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O52KdCmU0V2b",
        "outputId": "67b15c1f-76b6-48a6-df50-12b0c5429aad"
      },
      "source": [
        "prediction = model.dual_coef_.dot(np.power(model.gamma * model.support_vectors_.dot(scaled_query.T), model.degree)) + model.intercept_\n",
        "print(f'expected prediction value:\\t\\t{prediction[0]}')\n",
        "print(f'result prediction from encrypted value:\\t{prediction_enc.decrypt()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected prediction value:\t\t[1.77782917]\n",
            "result prediction from encrypted value:\t[1.7778570581410666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvZIk4ni9o7g"
      },
      "source": [
        "Yes! I know! The result is nothing short from amazing.\n",
        "\n",
        "We have been able to:\n",
        "- train an SVM model\n",
        "- encrypt our query\n",
        "- run the inference on encrypted query\n",
        "- and get result identical to one without encryption\n",
        "\n",
        "From here all client needs to do is to ask server what is the meaning of positive and negative values (in case of 2 class classification with SVM).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeiqGdRVBOc5",
        "outputId": "5f5b4995-c48a-46e4-d7c1-e6d8ae30d6ef"
      },
      "source": [
        "print(f'expected result using original model without encryption: {model.predict(scaled_query)}')\n",
        "print(f'result prediction from encrypted value:\\t\\t\\t {np.sign(prediction_enc.decrypt())}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "expected result using original model without encryption: ['1']\n",
            "result prediction from encrypted value:\t\t\t [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgkKB-zqByYf"
      },
      "source": [
        "Lets check the MSE and count the correct predictions comparing HE and unencrypted predictions on all available sound files in the dataset.\n",
        "Thing to note here the MSE is tiny, negligable!\n",
        "And all of the predictions are the same as the ones made on not encrypted query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qJBC2yx4smn",
        "outputId": "b91f403e-9302-4571-953b-f332791a8480"
      },
      "source": [
        "correct_results_counter = 0\n",
        "wrong_results_counter = 0\n",
        "results = pd.DataFrame(columns=['open_text', 'HE'])\n",
        "\n",
        "for features_array in X_train.iterrows():\n",
        "    enc_query = ts.ckks_vector(context, features_array[1].tolist())\n",
        "\n",
        "    inside_kernel = enc_query.matmul(support_vectors.T.tolist()) * gamma\n",
        "    kernel_result = inside_kernel.square() * inside_kernel\n",
        "\n",
        "    prediction_enc = kernel_result.dot(dual_coefficients[0].tolist()) + bias\n",
        "    \n",
        "    prediction_decrypted = prediction_enc.decrypt()\n",
        "    prediction = dual_coefficients.dot(np.power(gamma * support_vectors.dot(features_array[1].T), degree)) + bias\n",
        "    \n",
        "    results = results.append(\n",
        "        {\n",
        "            'open_text': prediction,\n",
        "            'HE': prediction_decrypted\n",
        "        },\n",
        "        ignore_index=True\n",
        "    )\n",
        "\n",
        "    if np.sign(prediction) == np.sign(prediction_decrypted):\n",
        "      correct_results_counter += 1\n",
        "    else:\n",
        "      wrong_results_counter += 1\n",
        "\n",
        "print(f'total correct: {correct_results_counter}')\n",
        "print(f'total wrong: {wrong_results_counter}')\n",
        "mse = ((results['open_text'] - results['HE'])**2).mean(axis=0)\n",
        "print(f'MSE: {mse}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total correct: 205\n",
            "total wrong: 0\n",
            "MSE: [1.16172214e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5cY8MJjCiGn"
      },
      "source": [
        "Links:\n",
        "- [More detailed overview of SVM and kernel functions](https://core.ac.uk/download/pdf/41757043.pdf)\n",
        "- [dot product explanation](https://arxiv.org/pdf/2012.13552.pdf)\n",
        "- [Support Vector Machines chapter from Python Data Science Handbook](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb#scrollTo=PDqscNUNJ7LV)\n",
        "- [Scikit Learn SVC documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
        "- [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html#example-svm-plot-separating-hyperplane-py)\n",
        "- [Python data science book](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
        "- [using custom kernels with SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html)\n",
        "\n",
        "- [Python speech features good place to find inspiration for feature extraction options](https://python-speech-features.readthedocs.io/en/latest/)\n",
        "- [Standard scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
      ]
    }
  ]
}